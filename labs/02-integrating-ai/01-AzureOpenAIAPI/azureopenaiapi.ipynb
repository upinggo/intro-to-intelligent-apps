{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Working with the Azure OpenAI API directly\n",
    "\n",
    "In this lab, we will perform a couple of simple calls to the Azure OpenAI API.\n",
    "- The first call will allow us to find out which Model Deployments are available for the Azure OpenAI API.\n",
    "- The second call will send a prompt to the Azure OpenAI API.\n",
    "\n",
    "This will also prove that everything is setup correctly and working for the rest of the labs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to retrieve values from the `.env` file which we will use to make calls to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://msgenaidaychina.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the API\n",
    "\n",
    "Now let's call the Azure OpenAI API with a prompt. To do this, we'll need the `id` of the Azure OpenAI deployment that contains our completion model. This should already be setup in the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct a URL to call so that you can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://msgenaidaychina.openai.azure.com//openai/deployments/msgenaidaygpt35/chat/completions?api-version=2024-02-01\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=\" + API_VERSION\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the full URL that we are going to call. This URL will use the specified deployment to call the **chat completions** API.\n",
    "\n",
    "Next, we will call the Azure OpenAI API using the URL above. We pass the API key in the HTTP header. We also send a JSON formatted body as part of the request which contains the *prompt* that we want to use to get a response from the OpenAI model. In this case, our prompt is \"Once upon a time\", which should cause the model to complete the prompt by generating a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \" there was a village called Green Hills. It was a beautiful and peaceful village, nestled in a valley surrounded by lush green hills. The villagers were mostly farmers and lived a simple and harmonious life.\\n\\nThe village was known for its rich and fertile land, and the farmers were able to grow a wide variety of fruits and vegetables. They took great pride in their work and worked hard to ensure that their crops were always bountiful.\\n\\nOne day, a terrible drought hit the village. The once lush and fertile land began to dry up, and the crops started to wither and die. The villagers were devastated, as they relied on their crops for their livelihood.\\n\\nThe villagers knew they had to come up with a solution to save their village. They gathered together and discussed the best course of action. After much deliberation, they decided to seek the help of an old wise woman who lived on the outskirts of the village. They had heard that she possessed great knowledge of the land and its cycles.\\n\\nThe wise woman listened to the villagers and then told them that the land was suffering from a lack of balance. She explained that they needed to perform a ritual to appease the spirits of the land and bring back the balance that had been lost.\\n\\nThe villagers followed the wise woman's instructions and carried out the ritual with great care and reverence. They prayed to the spirits, made offerings of their best crops, and asked for their forgiveness for any disrespect they may have shown to the land.\\n\\nMiraculously, the next day, a gentle rain began to fall. It was as if the land had heard the prayers of the villagers and was responding to their pleas for help. The rain continued to fall for days, nourishing the parched land and bringing it back to life.\\n\\nThe villagers were overjoyed as they saw their once-dying crops spring back to life. The village was saved, thanks to the wisdom of the old woman and the villagers' faith and unity.\\n\\nFrom that day on, the villagers made a solemn vow to always respect and honor the land. They learned an important lesson about the delicate balance of nature and the importance of working in harmony with the land rather than against it. And the village of Green Hills thrived once again, with more prosperity and abundance than ever before.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1714028114,\n",
      "  \"id\": \"chatcmpl-9HnIgNv80PtBdtpJqnt9A5JIIVD32\",\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"system_fingerprint\": \"fp_2f57f81c11\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 460,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 472\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": \"Once upon a time \"}]})\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the API call will be JSON data similar to the below example. Note that the response has been edited to make it easier to read.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-7wVxE2LNxaY6ZoxcWAmhiyrqaLZgf\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1694180212,\n",
    "  \"model\": \"gpt-35-turbo\",\n",
    "  \"prompt_filter_results\": [\n",
    "    {\n",
    "      \"prompt_index\": 0,\n",
    "      (content filter results removed for brevity)\n",
    "    }\n",
    "  ],\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \", there was a magical kingdom called Tildor ... )))\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 366,\n",
    "    \"prompt_tokens\": 13,\n",
    "    \"total_tokens\": 379\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here's some information about some of the more interesting pieces of data contained in that response.\n",
    "\n",
    "Key | Description\n",
    "--- | ---\n",
    "`model` | The model that was used to generate the response to the prompt\n",
    "`content` | This is the response that was generated by the OpenAI model. Note that the response example above was edited to remove most of the output to make it easier to read\n",
    "`finish_reason` | This is the reason that the model stopped generating the response. In this case, `stop` indicates the model determined it had fully completed the response without hitting any limits\n",
    "`completion_tokens` | The number of tokens that were used in generating the response\n",
    "`prompt_tokens` | The number of tokens that were consumed by the prompt\n",
    "`total_tokens` | The total number of tokens that were consumed by the request (`prompt_tokens` + `completion_tokens`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we used the Azure OpenAI API directly to send a prompt to an OpenAI model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we will look at using the OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [OpenAI Packages/Libraries](../02-OpenAIPackages/openai.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
